{
  "slug": "10-systems-design-concepts-i-wish-id-learned-before-senior-year",
  "title": "10 Systems Design Concepts I Wish I'd Learned Before Senior Year",
  "description": "A clear, foundational look at the systems design concepts most students never learn but every real-world engineer eventually relies on.",
  "date": "2025-12-01T00:00:00.000Z",
  "coverImageUrl": "https://raw.githubusercontent.com/sbpete/blog/main/images/10-systems-design-concepts-i-wish-id-learned-before-senior-year-1764590983316-sys_design.png",
  "tags": [
    "Systems Design",
    "Career",
    "Software Engineering"
  ],
  "contentMarkdown": "Before I start, this is just my opinion. Whether you're just starting to use AI or it is already part of your daily work, I hope this helps you think about how it is really changing things.\n\nAI promises to speed everything up, from writing code to generating reports to automating workflows. But how useful it actually is depends on how people use it. Some people get huge productivity boosts. Others get frustrated or even slower.\n\nA recent [ACM study](https://dl.acm.org/doi/pdf/10.1145/3643795.3648379) found that trust, experience, and understanding play a big role in how effective AI really is. The more you know its limits, the more you get out of it.\n\n## The New Stress of “Speed”\n\nSoftware development has always been full of estimates. How long until it is done? How much effort will it take?\n\nNow new tools claim to make everything faster. Product managers expect quicker delivery. Executives expect more output. Engineers are left trying to keep up.\n\nThe result is less testing, fewer reviews, and more chaos. Code gets shipped that isn’t ready. Tech stacks change weekly. Managers are stressed about picking the right tools and developers are burned out trying to hit unrealistic goals.\n\nAI was supposed to make things easier, but often it just shifts the pressure somewhere else. It’s not that AI is bad. It’s that expectations grow faster than what is realistic. Everyone wants instant results. But real software still takes time to test, integrate, and maintain.\n\n## When Engineers Stop Learning\n\nIf every time something breaks we ask AI to fix it, we stop learning how to debug and think critically.\n\nDebugging is how you build intuition. You learn how systems connect and where assumptions fail. That skill fades fast if you let AI think for you.\n\nThe scary part is that AI code looks correct. It compiles, runs, and may even pass your tests. But it might be subtly wrong in ways that are hard to spot. When you don’t understand what it is doing, you can’t fix it later.\n\nAI can’t replace problem solving. It can only hide it behind convenience.\n\nThe best developers will still be the ones who know how to think, not just how to prompt.\n\n## Losing Sight of Business Value\n\nA lot of AI projects sound impressive but have little real purpose. Companies love to show off “AI-powered” features that don’t actually help users.\n\nIt’s easy to confuse building something with building something valuable.\n\nAs engineers, our job is not to write code. It is to create value — something people use, enjoy, or pay for. If AI doesn’t help with that, it’s just noise.\n\nOnly humans can connect technology to real needs. AI doesn’t understand business trade-offs, users, or context. Without that judgment, teams can waste months chasing trends that don’t matter.\n\n## The Culture Gap\n\nAI has made it even harder for engineers, managers, and executives to stay aligned.\n\nLeadership hears “AI writes code instantly” and assumes timelines should shrink. Engineers know that even if AI writes code, it doesn’t design, test, or deploy it.\n\nThat misunderstanding creates tension. Developers feel rushed. Managers feel behind. Executives wonder why things still take time.\n\nThe fix isn’t more AI. The fix is clearer communication about what AI can and cannot do.\n\n## Using AI the Right Way\n\nEthan Mollick’s [Co-Intelligence](https://www.co-intelligence.com/) describes two ways to work with AI: the centaur and the cyborg.\n\nThe centaur model works better. Humans stay in control and use AI as support. AI handles speed and repetition while humans handle judgment and direction.\n\nTo make that work, the fundamentals of engineering still matter:\n\n**Testing:** Define what correct means.\n**Modularity:** Keep systems clean and understandable.\n**Code reviews:** Humans catch what AI cannot.\n**Documentation:** Don’t rely on AI to explain everything later.\n\nThese basics have always mattered. AI doesn’t change that. If anything, it makes them more important.\n\n## The Real Role of AI\n\nAI won’t take entire jobs. It will take the boring parts of them. That’s a good thing if you use it correctly.\n\nThe best engineers will use AI as leverage, not a crutch.\n\nAI gives us a chance to focus on what actually matters: building useful things, solving real problems, and thinking deeply about how tech fits into the world.\n\nThe danger is not that AI replaces us. The danger is that we stop thinking critically because it’s easier not to.\n\n## Further Reading\n\n[Things They Didn’t Teach You About Software Engineering](https://vadimkravcenko.com/shorts/things-they-didnt-teach-you/)\n[ACM Study on LLM Perception and Usefulness](https://dl.acm.org/doi/pdf/10.1145/3643795.3648379)\n*Co-Intelligence* by Ethan Mollick\n\nAI won’t destroy software engineering, but it will make it obvious who truly understands it."
}

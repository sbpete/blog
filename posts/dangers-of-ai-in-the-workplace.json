{
  "slug": "dangers-of-ai-in-the-workplace",
  "title": "Dangers of AI in the Workplace",
  "description": "AI won’t destroy software engineering, but it will make it obvious who truly understands it.",
  "date": "2025-11-04T00:00:00.000Z",
  "coverImageUrl": "https://raw.githubusercontent.com/sbpete/blog/main/images/temp-1762293833356-boards.png",
  "tags": [
    "AI",
    "Software Engineering",
    "Product Management",
    "Project Management"
  ],
  "contentMarkdown": "# The Dangers of AI in the Workplace\n\nBefore I start, this is just my opinion. Whether you're just starting to use AI or it’s already part of your daily work, I hope this helps you think about how it’s really changing things.\n\nAI promises to speed everything up — writing code, generating reports, automating workflows. But how useful it actually is depends on how people use it. Some people get huge productivity boosts. Others get frustrated or even slower. A recent [ACM study](https://dl.acm.org/doi/pdf/10.1145/3643795.3648379) found that trust, experience, and understanding play a big role in how effective AI really is. The more you know its limits, the more you get out of it.\n\n## The New Stress of “Speed”\n\nSoftware development has always been full of estimates. How long until it’s done? How much effort will it take? But now, new tools claim to make everything faster. Product managers expect quicker delivery. Executives expect more output. Engineers are left trying to keep up.\n\nThe result? Less testing, fewer reviews, more chaos. Code gets shipped that isn’t ready. Tech stacks change weekly. Managers are stressed about picking the right tools, and developers are burned out trying to hit unrealistic goals. AI was supposed to make things easier, but often it just shifts the pressure somewhere else.\n\nIt’s not that AI is bad — it’s that expectations grow faster than what’s realistic. Everyone wants instant results. But real software still takes time to test, integrate, and maintain.\n\n## When Engineers Stop Learning\n\nIf every time something breaks we just ask AI to fix it, we stop learning how to debug and think critically. Debugging is how you build intuition. You learn how systems connect and where assumptions fail. That skill fades fast if you let AI do all the thinking.\n\nThe scary part is that AI code *looks* correct. It compiles, it runs, maybe even passes your tests. But it might be subtly wrong in ways that are hard to spot. And when you don’t understand what it’s doing, you can’t fix it later.\n\nAI can’t replace problem-solving. It can only hide it behind convenience. The best developers will still be the ones who know how to think — not just how to prompt.\n\n## Losing Sight of Business Value\n\nA lot of AI projects sound impressive but have little real purpose. Companies love to show off “AI-powered” features that don’t actually help users. It’s easy to confuse building *something* with building *something valuable*.\n\nAs engineers, our job isn’t to write code. It’s to create value — something people use, enjoy, or pay for. If AI doesn’t help with that, it’s just noise.\n\nOnly humans can connect technology to real needs. AI doesn’t understand business trade-offs, users, or context. Without that judgment, teams can waste months chasing trends that don’t matter.\n\n## The Culture Gap\n\nAI has made it even harder for engineers, managers, and executives to stay aligned. Leadership hears “AI writes code instantly” and assumes timelines should shrink. But engineers know that even if AI writes code, it doesn’t design, test, or deploy it.\n\nThat misunderstanding creates tension. Developers feel rushed, managers feel behind, and executives wonder why things still take time. The fix isn’t more AI — it’s clearer communication about what AI can and can’t do.\n\n## Using AI the Right Way\n\nEthan Mollick’s *[Co-Intelligence](https://www.co-intelligence.com/)* describes two ways to work with AI: the **cyborg**, where human and AI work blend completely, and the **centaur**, where humans stay in control and use AI as support. The centaur model works better. Humans handle judgment and direction. AI handles speed and repetition.\n\nTo make that work, the fundamentals of engineering still matter:\n- **Testing:** Define what correct means.\n- **Modularity:** Keep systems clean and understandable.\n- **Code reviews:** Humans catch what AI can’t.\n- **Documentation:** Don’t rely on AI to explain everything later.\n\nThese basics have always mattered, and AI doesn’t change that. If anything, it makes them more important.\n\n## The Real Role of AI\n\nAI won’t take entire jobs — it’ll take the boring parts of them. That’s a good thing if you use it right. The best engineers will learn to use AI as leverage, not a crutch.\n\nAI gives us a chance to focus on what actually matters: building useful things, solving real problems, and thinking deeply about how tech fits into the world. The danger isn’t that AI replaces us — it’s that we stop thinking critically because it’s easier not to.\n\n**Further Reading**\n\n- [“Things They Didn’t Teach You About Software Engineering”](https://vadimkravcenko.com/shorts/things-they-didnt-teach-you/)\n- [ACM Study on LLM Perception and Usefulness](https://dl.acm.org/doi/pdf/10.1145/3643795.3648379)\n- *Co-Intelligence* by Ethan Mollick\n\nAI won’t destroy software engineering, but it will make it obvious who truly understands it."
}

{
  "slug": "digging-a-little-deeper-into-mcp",
  "title": "Digging a Little Deeper into MCP",
  "description": "MCP is the plumbing that makes agent tool calls real, and understanding the plumbing is how you keep the magic under control.",
  "date": "2026-03-01T00:00:00.000Z",
  "coverImageUrl": "https://raw.githubusercontent.com/sbpete/blog/main/images/digging-a-little-deeper-into-mcp-1772306993499-gemini_generated_image_h8s8ryh8s8ryh8s8.png",
  "tags": [
    "AI",
    "Software Engineering",
    "MCP"
  ],
  "contentMarkdown": "Quick note: If you already have a solid mental model of agents, tool calls, and MCP, skip ahead to the JSON-RPC section for the under-the-hood details.\n\nIt’s hard to miss it at this point: agents aren’t a speculative next step in AI. They’re already here. But the word “agent” is annoyingly slippery. Depending on who you ask, it can mean everything from “an LLM with a loop” to “a fully autonomous system.” A practical way to think about agents is simpler: they’re AI systems that can use tools.\n\nThat capability comes with a tradeoff. The moment you let an AI call tools, you’re delegating some degree of authority to act on your behalf. More tools usually means more power, and more ways things can go wrong if you don’t enforce guardrails. It’s a bit like casting a spell. If your instructions are vague, or your safeguards are weak, you can end up in a Sorcerer’s Apprentice situation where the system keeps “helping” long after it should’ve stopped.\n\n## How agents actually work\nLLMs, by themselves, only generate text. For an AI system to do anything meaningful, write a file, click a button, send a request, play music, it needs access to tools that can execute actions in the real world (or at least inside other software).\n\nThose tools often map to existing functions in an application. For example, a design tool like Figma might expose an action like “create a rectangle” or “set fill color to red.” The problem is that every app exposes a different set of functions, with different arguments, constraints, and error cases. Meanwhile, LLM output is inherently messy. It’s probabilistic, sometimes ambiguous, and not guaranteed to be structured correctly.\n\nThat’s why most real agents rely on a developer-built harness around the model. The harness is the glue code that turns “LLM text” into reliable, typed, bounded actions. If the LLM is the brain, the harness is the body (and a big chunk of the nervous system). It interprets outputs, validates inputs, enforces policies, sets hard limits, retries safely, and decides what actually gets executed.\n\n## Where MCP fits in\nMCP has emerged as a de facto standard for tool calling, but it can still feel fuzzy, especially if you only hear analogies like “a USB port for AI” or “a common language.” The useful question is: where does MCP actually sit in the stack?\n\nUnder the hood, MCP uses JSON-RPC 2.0. In plain terms, JSON-RPC is a lightweight protocol for invoking procedures across a boundary (often a process boundary, sometimes a machine boundary) using JSON messages. The core idea of RPC is right in the name: you call something “remote” as if it were local, and the caller typically waits for a response.\n\nIn an MCP flow, it looks roughly like this:\n\n1) The AI system decides which tool it wants to use, based on the user request and the tools it knows exist\n\n2) The harness turns the model’s intent into a structured JSON-RPC request\n\n3) A client sends that request to an MCP server\n\n4) The server executes the tool synchronously and returns a JSON-RPC response\n\n5) The harness can manage concurrency, handle failures, apply limits, and aggregate results before the model continues\n\nJSON-RPC messages generally come in three flavors: requests, responses, and notifications. You’ll usually see fields like:\n\n\\text{\"id\"}: correlates a response to a specific request\n\n\\text{\"method\"}: which procedure you’re calling remotely\n\n\\text{\"params\"}: the input arguments (or \\text{\"result\"} on the way back)\n\nHere’s a concrete example of a tool call request:\n\n`\njson\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\": \"tools/call\",\n  \"params\": {\n    \"name\": \"search_web\",\n    \"arguments\": { \"query\": \"AI trends\" }\n  }\n}\n`\n\nThe key takeaway is that MCP isn’t “the agent” and it isn’t “the harness.” MCP is the standard wire-level shape of tool invocation. It is a consistent way for the harness or client to ask a server to run a tool and to receive a structured response back.\n\n## Why this matters (and how to keep up)\nA lot of agent discourse stays at the analogy level. Analogies help you get started, but they can also blur the boundaries that matter in real systems. When you understand where MCP lives, you stop treating the agent as magic and start seeing a stack with separable parts:\n\nThe model produces intentions\n\nThe harness enforces reality, safety, and structure"
}